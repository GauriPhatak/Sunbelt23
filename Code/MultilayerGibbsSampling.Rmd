---
title: "Algorithm for Simultaneous Missing Data Imputation and Community Detection"
output: pdf_document
date: "2024-01-24"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

source("HelperFuncs.R")

```

## Type of missing data

Assumption: Missing at random. Lends itself to imputation problems

Handling continuous data for now.

## Multi layer Gibbs sampling

Outer posterior: Missing data handling

Inner posterior: Community detection

Simplifying assumptions: 

1. Single community : Only the inner layer is utilized
2. No missing data : Only the outer layer is utilized

Identify the distribution of missing data

Criterion for convergence of the Gibbs sampler.

Probability based community assignment

Distributions of communities.

Gives an idea of community assignment in relation to the missing data.

Probability and missing data values can give a reason for difficulty to place nodes. Gives a confidence for different possible imputed values of the missing data and the difficulty to place the nodes.

##### Steps to take:

* Start with known communities and full data.Different ways to generate data. Is there correlation between communities and the data/missing data.
    - Come up with a different ways the data can be missing. Related to the community assignment 
* Multiple layer Gibbs sampler

TODO:

1. Understanding how multilayer Gibbs sampling works.

2. Create inner and outer layer based on ERGM model or Community detection. Two possible types of communities.
  a. Communities are a categorical variable. Each node belongs to one community
  b. Probability based communities. Can relate this to missing data. Give a confidence of community assignment based on different possible values of imputed data.
  
3. Two possibilities Likelihood based methods or Data imputation.
  
  
## Understadning method used by thesis* for missing data imputation.

a: Relies on combining FCS framework and network model.

b: Not many models available for imputing missing data in networks. Especially using ERGM model.

## MultiLayer Gibbs sampling:

1. Gibbs sampling for missing data:
  a. Sample from Conditional distribution instead of joint distribution.
  

2. Adding a layer to Gibbs sampling for ERGM model.



### Starter code for multilevel imputation.

Tracking:

1. Missing data

2. Communities

  a. ARI compared to priginal
  
  b. ARI compared to previous iteration.



```{r}

niter= 100

# network simulation with 3 groups 100 nodes and connectivity defined by B vector. Co-variates defined as below.
##Synthetic population parameters
## Going to use only undirected network
## Setting the required coefficient values
#### Example for within cluster probability is higher than between cluster.
k <- 3
N <- 100
pC = c(0.3,0.4,0.3)
B = c(0.7,0.02,0.7,0.03,0.02,0.7)

## assigning node community with probability pC for a node assigned to for each community. hence pC and has to eb of length k
C = sample(1:k,N,replace = TRUE, prob = pC)
coefs = c(prob2logit(B))

## Simulating the basis network with clusters
g.sim <- NetworkSim(N,FALSE,B,C, NULL, coefs)

plot( g.sim,
      edge.col = adjustcolor('black',alpha.f = 0.5),
      #main=paste('homophily =', round(logit2prob(Hseq[i]), digits = 2)),
      vertex.col = g.sim %v% 'Cluster')

## Network with one categorical Variables

### Categorical variable correlated to the assigned clusters and same number of levels.
## Using LOTR books.
cat <- c("FOTR","TT","ROTK")
pCat <- list(c(0.6,0.2,0.2), # Cluster 1
             c(0.2,0.6,0.2), # Cluster 2
             c(0.2,0.2,0.6)) # Cluster 3
## Assigning categorical data based on cluster assignments.
## Node in cluster one thinks FOTR is the best book with probability of 0.6, TT with prob 0.1 and ROTK with prob 0.3
g.sim %v% 'LOTR' <- NA
j <- 1
for (i in 1:k) {
  bk <- g.sim %v% 'LOTR'
  bk[which(g.sim %v% 'Cluster' == i)] <- sample(cat,
                                                 length( which(g.sim %v% 'Cluster' == i)), 
                                                 prob = pCat[[i]], 
                                                 replace = TRUE)
  g.sim %v% 'LOTR' <- bk

}

g.sim <- asIgraph(g.sim)
### Categorical variable correlated to the assigned clusters and different number of levels.(binary variable where one is correlated to two clusters and 2nd is correlated to the last cluster.)

### Categorical variables not correlated to the assigned clusters and same number of levels.
### Categorical variables not correlated to the assigned clusters and different number of levels.(binary levels with no correlation.)

## Network with one continuous Variable

### Continuous variable correlated to the assigned clusters and different distributions for each cluster.
### Continuous variable correlated to the assigned clusters and same distribution for all clusters.



# running regularized spectral clustering on the original network without any covariate information.
origmem <- RegSpectralClust(g.sim, 3,regularize = TRUE)

mclust::adjustedRandIndex(origmem, V(g.sim)$Cluster)

## Covariate assisted spectral clustering 
## Since we are using categorical data we have to perform one hot encoding.
X <- as.matrix(V(g.sim)$LOTR)
Xdum <- as.matrix(data.frame(predict(dummyVars("~.", data = X ), newdata <- X)))
origmemCov <- CovAssistedSpecClust(G = g.sim, Xdum, 3,Regularize =TRUE, alpha =NA, type ="non-assortative")

plot.igraph( g.sim,
      edge.col = adjustcolor('black',alpha.f = 0.5),
      vertex.color = as.factor(V(g.sim)$LOTR))

plot.igraph( g.sim,
      edge.col = adjustcolor('black',alpha.f = 0.5),
      vertex.color = origmem)

plot.igraph( g.sim,
      edge.col = adjustcolor('black',alpha.f = 0.5),
      vertex.color = origmemCov)

plot.igraph( g.sim,
      edge.col = adjustcolor('black',alpha.f = 0.5),
      vertex.color = V(g.sim)$Cluster)

## Check correlation between the covariates and the community generated.

table(origmemCov, V(g.sim)$LOTR)

table(origmemCov, V(g.sim)$Cluster)

table(V(g.sim)$LOTR, V(g.sim)$Cluster)

# create missingness in simulated networks

## Missingness created randomly.
pctMsng <- c(1,5,7, 10)

for(p in pctMsng){
  
  Midx <- sample(1:N,ceiling(p*N/100))
  print(Midx)
  X[Midx] <- NA
  pmax(as.matrix(table(X,V(g.sim)$Cluster, useNA = "no")))
  Xdum <- as.matrix(data.frame(predict(dummyVars("~.", data = X ), 
                                       newdata <- X)))
  
}

# Impute missing values in NW using mean imputation for continous covariate. 

# Use spectral CD algorithm to find the initial communities.


## Loop
## Missingness based on mean imputation based on assigned communities.
## Update communities based on Spectral clustering with covariates algorithm.
## Future:
### Using nodecov for quatitative and nodefactor for categorical variables when I eventually use ERGM for model fitting.
```

















